# file_bed_server/main.py
import base64
import os
import uuid
import time
from datetime import datetime, timedelta
from contextlib import asynccontextmanager
from fastapi import FastAPI, HTTPException, Request
from fastapi.responses import JSONResponse
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel
import logging
from apscheduler.schedulers.background import BackgroundScheduler

# --- åŸºç¡€é…ç½® ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# --- è·¯å¾„é…ç½® ---
# å°†ä¸Šä¼ ç›®å½•å®šä½åˆ° main.py æ–‡ä»¶çš„åŒçº§ç›®å½•
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
UPLOAD_DIR = os.path.join(BASE_DIR, "uploads")
API_KEY = "your_secret_api_key"  # ç®€å•çš„è®¤è¯å¯†é’¥
CLEANUP_INTERVAL_MINUTES = 1 # æ¸…ç†ä»»åŠ¡è¿è¡Œé¢‘ç‡ï¼ˆåˆ†é’Ÿï¼‰
FILE_MAX_AGE_MINUTES = 10 # æ–‡ä»¶æœ€å¤§ä¿ç•™æ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰

# --- æ¸…ç†å‡½æ•° ---
def cleanup_old_files():
    """éå†ä¸Šä¼ ç›®å½•å¹¶åˆ é™¤è¶…è¿‡æŒ‡å®šæ—¶é—´çš„æ–‡ä»¶ã€‚"""
    now = time.time()
    cutoff = now - (FILE_MAX_AGE_MINUTES * 60)
    
    logger.info(f"æ­£åœ¨è¿è¡Œæ¸…ç†ä»»åŠ¡ï¼Œåˆ é™¤æ—©äº {datetime.fromtimestamp(cutoff).strftime('%Y-%m-%d %H:%M:%S')} çš„æ–‡ä»¶...")
    
    deleted_count = 0
    try:
        for filename in os.listdir(UPLOAD_DIR):
            file_path = os.path.join(UPLOAD_DIR, filename)
            if os.path.isfile(file_path):
                try:
                    file_mtime = os.path.getmtime(file_path)
                    if file_mtime < cutoff:
                        os.remove(file_path)
                        logger.info(f"å·²åˆ é™¤è¿‡æœŸæ–‡ä»¶: {filename}")
                        deleted_count += 1
                except OSError as e:
                    logger.error(f"åˆ é™¤æ–‡ä»¶ '{file_path}' æ—¶å‡ºé”™: {e}")
    except Exception as e:
        logger.error(f"æ¸…ç†æ—§æ–‡ä»¶æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}", exc_info=True)

    if deleted_count > 0:
        logger.info(f"æ¸…ç†ä»»åŠ¡å®Œæˆï¼Œå…±åˆ é™¤äº† {deleted_count} ä¸ªæ–‡ä»¶ã€‚")
    else:
        logger.info("æ¸…ç†ä»»åŠ¡å®Œæˆï¼Œæ²¡æœ‰æ‰¾åˆ°éœ€è¦åˆ é™¤çš„æ–‡ä»¶ã€‚")


# --- FastAPI ç”Ÿå‘½å‘¨æœŸäº‹ä»¶ ---
scheduler = BackgroundScheduler(timezone="UTC")

@asynccontextmanager
async def lifespan(app: FastAPI):
    """åœ¨æœåŠ¡å™¨å¯åŠ¨æ—¶å¯åŠ¨åå°ä»»åŠ¡ï¼Œåœ¨å…³é—­æ—¶åœæ­¢ã€‚"""
    # å¯åŠ¨è°ƒåº¦å™¨å¹¶æ·»åŠ ä»»åŠ¡
    scheduler.add_job(cleanup_old_files, 'interval', minutes=CLEANUP_INTERVAL_MINUTES)
    scheduler.start()
    logger.info(f"åå°æ–‡ä»¶æ¸…ç†ä»»åŠ¡å·²å¯åŠ¨ï¼Œæ¯ {CLEANUP_INTERVAL_MINUTES} åˆ†é’Ÿè¿è¡Œä¸€æ¬¡ã€‚")
    yield
    # å…³é—­è°ƒåº¦å™¨
    scheduler.shutdown()
    logger.info("åå°æ–‡ä»¶æ¸…ç†ä»»åŠ¡å·²åœæ­¢ã€‚")


app = FastAPI(lifespan=lifespan)

# --- ç¡®ä¿ä¸Šä¼ ç›®å½•å­˜åœ¨ ---
if not os.path.exists(UPLOAD_DIR):
    os.makedirs(UPLOAD_DIR)
    logger.info(f"ä¸Šä¼ ç›®å½• '{UPLOAD_DIR}' å·²åˆ›å»ºã€‚")

# --- æŒ‚è½½é™æ€æ–‡ä»¶ç›®å½•ä»¥æä¾›æ–‡ä»¶è®¿é—® ---
app.mount(f"/uploads", StaticFiles(directory=UPLOAD_DIR), name="uploads")

# --- Pydantic æ¨¡å‹å®šä¹‰ ---
class UploadRequest(BaseModel):
    file_name: str
    file_data: str # æ¥æ”¶å®Œæ•´çš„ base64 data URI
    api_key: str | None = None

# --- API ç«¯ç‚¹ ---
@app.post("/upload")
async def upload_file(request: UploadRequest, http_request: Request):
    """
    æ¥æ”¶ base64 ç¼–ç çš„æ–‡ä»¶å¹¶ä¿å­˜ï¼Œè¿”å›å¯è®¿é—®çš„ URLã€‚
    """
    # ç®€å•çš„ API Key è®¤è¯
    if API_KEY and request.api_key != API_KEY:
        raise HTTPException(status_code=401, detail="æ— æ•ˆçš„ API Key")

    try:
        # 1. è§£æ base64 data URI
        header, encoded_data = request.file_data.split(',', 1)
        
        # 2. è§£ç  base64 æ•°æ®
        file_data = base64.b64decode(encoded_data)
        
        # 3. ç”Ÿæˆå”¯ä¸€æ–‡ä»¶åä»¥é¿å…å†²çª
        file_extension = os.path.splitext(request.file_name)[1]
        if not file_extension:
            # å°è¯•ä» header ä¸­è·å– mime ç±»å‹æ¥çŒœæµ‹æ‰©å±•å
            import mimetypes
            mime_type = header.split(';')[0].split(':')[1]
            guessed_extension = mimetypes.guess_extension(mime_type)
            file_extension = guessed_extension if guessed_extension else '.bin'

        unique_filename = f"{uuid.uuid4()}{file_extension}"
        file_path = os.path.join(UPLOAD_DIR, unique_filename)

        # 4. ä¿å­˜æ–‡ä»¶
        with open(file_path, "wb") as f:
            f.write(file_data)
        
        # 5. è¿”å›æˆåŠŸä¿¡æ¯å’Œå”¯ä¸€æ–‡ä»¶å
        logger.info(f"æ–‡ä»¶ '{request.file_name}' å·²æˆåŠŸä¿å­˜ä¸º '{unique_filename}'ã€‚")
        
        return JSONResponse(
            status_code=200,
            content={"success": True, "filename": unique_filename}
        )

    except (ValueError, IndexError) as e:
        logger.error(f"è§£æ base64 æ•°æ®æ—¶å‡ºé”™: {e}")
        raise HTTPException(status_code=400, detail=f"æ— æ•ˆçš„ base64 data URI æ ¼å¼: {e}")
    except Exception as e:
        logger.error(f"å¤„ç†æ–‡ä»¶ä¸Šä¼ æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"å†…éƒ¨æœåŠ¡å™¨é”™è¯¯: {e}")

@app.get("/")
def read_root():
    return {"message": "LMArena Bridge æ–‡ä»¶åºŠæœåŠ¡å™¨æ­£åœ¨è¿è¡Œã€‚"}

# --- ä¸»ç¨‹åºå…¥å£ ---
if __name__ == "__main__":
    import uvicorn
    logger.info("ğŸš€ æ–‡ä»¶åºŠæœåŠ¡å™¨æ­£åœ¨å¯åŠ¨...")
    logger.info("   - ç›‘å¬åœ°å€: http://127.0.0.1:5180")
    logger.info(f"   - ä¸Šä¼ ç«¯ç‚¹: http://127.0.0.1:5180/upload")
    logger.info(f"   - æ–‡ä»¶è®¿é—®è·¯å¾„: /uploads")
    uvicorn.run(app, host="0.0.0.0", port=5180)